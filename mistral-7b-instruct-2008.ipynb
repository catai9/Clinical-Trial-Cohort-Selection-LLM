{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a7f270-a220-443e-b77f-e9a0c5535703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tai/anaconda3/envs/fastchat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time \n",
    "import gc\n",
    "\n",
    "from llm_utils import LLMModel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f1e211-ba49-4069-8a2d-a4fadf5ba3f5",
   "metadata": {},
   "source": [
    "## n2c2_2008 Intuitive Model Comparison Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949c724-26e1-44cf-bfa3-1818fbcc1a7f",
   "metadata": {},
   "source": [
    "#### STARTING SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652df0aa-4165-462f-94e8-e2ce58b30739",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "log_file_name = f'server2-{date_str}-n2c2-tasks-2008-intuitive-llm-model-runs.txt'\n",
    "example_names = ['example_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253317a9-3d20-444c-9ff2-559ecc9d3968",
   "metadata": {},
   "source": [
    "#### MISTRAL7B-INSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5acf87-56d5-40ee-83e7-509fd6a53acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start = time.time()\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Starting to run server2 models on n2c2_2008 data... \\n')\n",
    "    f.write(f'Running mistral7B instruct model on n2c2_2018 data... \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d972103a-df20-4a32-a687-4a2a7710eff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 06:12:54,136 - n2c2 - INFO - Parameters: \n",
      "{device: {device: cuda, load_8bit: true, num_gpus: 1}, general: {resources: {section_titles: resources/n2c2_sections_subpart.txt},\n",
      "    test: {dir: data/n2c2_2008_data, files: [n2c2_2008_test.csv]}, train: {dir: data/n2c2_2008_data,\n",
      "      files: [n2c2_2008_train.csv]}, val: {dir: data/n2c2_2008_data, files: [n2c2_2008_val.csv]}},\n",
      "  generation: {echo: false, judge_sent_end: false, max_new_tokens: 256, model_path: mistralai/Mistral-7B-Instruct-v0.1,\n",
      "    repetition_penalty: 1.0, temperature: 0}, intuitive_Asthma: {few_shot: true},\n",
      "  intuitive_CAD: {few_shot: true}, intuitive_CHF: {few_shot: true}, intuitive_Depression: {\n",
      "    few_shot: true}, intuitive_Diabetes: {few_shot: true}, intuitive_GERD: {few_shot: true},\n",
      "  intuitive_Gallstones: {few_shot: true}, intuitive_Gout: {few_shot: true}, intuitive_Hypercholesterolemia: {\n",
      "    few_shot: true}, intuitive_Hypertension: {few_shot: true}, intuitive_Hypertriglyceridemia: {\n",
      "    few_shot: true}, intuitive_OA: {few_shot: true}, intuitive_OSA: {few_shot: true},\n",
      "  intuitive_Obesity: {few_shot: true}, intuitive_PVD: {few_shot: true}, intuitive_Venous Insufficiency: {\n",
      "    few_shot: true}, logger: !!python/object/apply:logging.getLogger [n2c2], main: {\n",
      "    task_dirs: [few_shot_n2c2_2008_tasks]}, retrieval: {EMD: {distance_type: cosine,\n",
      "      embedding_type: fasttext}, OVERLAP: {distance_type: cosine, embedding_type: fasttext},\n",
      "    lowercase: true, method: OVERLAP, use_cuda: false}, textual_Asthma: {few_shot: true},\n",
      "  textual_CAD: {few_shot: true}, textual_CHF: {few_shot: true}, textual_Depression: {\n",
      "    few_shot: true}, textual_Diabetes: {few_shot: true}, textual_GERD: {few_shot: true},\n",
      "  textual_Gallstones: {few_shot: true}, textual_Gout: {few_shot: true}, textual_Hypercholesterolemia: {\n",
      "    few_shot: true}, textual_Hypertension: {few_shot: true}, textual_Hypertriglyceridemia: {\n",
      "    few_shot: true}, textual_OA: {few_shot: true}, textual_OSA: {few_shot: true},\n",
      "  textual_Obesity: {few_shot: true}, textual_PVD: {few_shot: true}, textual_Venous Insufficiency: {\n",
      "    few_shot: true}}\n",
      "\n",
      "2024-03-02 06:12:54,136 - n2c2 - INFO - available devices: 1\n",
      "2024-03-02 06:12:54,138 - n2c2 - INFO - current device: 0\n",
      "2024-03-02 06:12:54,280 - n2c2 - INFO - Load fastchat model mistralai/Mistral-7B-Instruct-v0.1\n",
      "100%|██████████| 2/2 [01:29<00:00, 44.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralAttention(\n",
      "          (q_proj): CLinear()\n",
      "          (k_proj): CLinear()\n",
      "          (v_proj): CLinear()\n",
      "          (o_proj): CLinear()\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): CLinear()\n",
      "          (up_proj): CLinear()\n",
      "          (down_proj): CLinear()\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): CLinear()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 06:14:26,504 - n2c2 - INFO - Load retriever\n"
     ]
    }
   ],
   "source": [
    "mistral7b_instruct_model = LLMModel(\n",
    "    config_file='./model-configs/mistral7b_instruct_n2c2_2008.yml',\n",
    "    title_prefix='3-n2c2_2008-intuitive-few-shot-mistral-7b-instruct', \n",
    "    task_names = ['intuitive_Asthma', 'intuitive_CAD', 'intuitive_CHF', 'intuitive_Depression', 'intuitive_Diabetes', \n",
    "              'intuitive_Gallstones', 'intuitive_GERD', 'intuitive_Gout', 'intuitive_Hypertension', 'intuitive_Hypercholesterolemia',\n",
    "              'intuitive_Hypertriglyceridemia', 'intuitive_OA', 'intuitive_Obesity', 'intuitive_OSA', 'intuitive_PVD',\n",
    "              'intuitive_Venous Insufficiency'],\n",
    "    is_multiclass=True)\n",
    "\n",
    "mistral7b_instruct_model.setupModelForPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67583f20-b19e-4469-8fed-0cee39c038ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 06:14:38,808 - n2c2 - INFO - Load data\n",
      "2024-03-02 06:14:38,865 - n2c2 - INFO - Load data\n",
      "2024-03-02 06:14:38,885 - n2c2 - INFO - Load data\n",
      "  0%|          | 0/438 [00:00<?, ?it/s]/home/tai/n2c2_test/llm_utils.py:211: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'N' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  prediction_df.loc[prediction_df['id'] == text_id, task_name] = pred_answer\n",
      " 24%|██▎       | 103/438 [07:33<24:46,  4.44s/it]"
     ]
    }
   ],
   "source": [
    "temp_start = time.time()\n",
    "elapsed_time = temp_start - model_start\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Finished setting up mistral7b_instruct_model model on n2c2_2008 data: {elapsed_time}\\n')\n",
    "\n",
    "for example_name in example_names:\n",
    "    temp_end = time.time()\n",
    "    elapsed_time = temp_end - temp_start\n",
    "\n",
    "    mistral7b_instruct_model.load2006and2008ModelPredictions(example_name)\n",
    "\n",
    "    with open(log_file_name, 'a') as f:\n",
    "        f.write(f'Finished running {example_name} for mistral7b_instruct_model model on n2c2_2008 data: {elapsed_time}\\n')\n",
    "    \n",
    "    temp_start = time.time()\n",
    "        \n",
    "\n",
    "model_end = time.time()\n",
    "elapsed_time = model_end - model_start\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Finished running mistral7b_instruct_model model on n2c2_2008 data: {elapsed_time}\\n')\n",
    "\n",
    "del mistral7b_instruct_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba660b-675f-44ff-a4b2-102cafdb7359",
   "metadata": {},
   "source": [
    "#### ENDING CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9ebac-25e9-4b10-a01e-e09a0a93db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "elapsed_time = end - model_start\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Finished running models on server 2 on n2c2_2008 data for textual tasks: {elapsed_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f97bd3-9e78-450b-abc9-4cbc02bb8c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48f261d",
   "metadata": {},
   "source": [
    "## n2c2_2008 Textual Model Comparison Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74857a",
   "metadata": {},
   "source": [
    "#### STARTING SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "log_file_name = f'server1-{date_str}-n2c2-tasks-2008-textual-llm-model-runs.txt'\n",
    "example_names = ['example_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4446a1d",
   "metadata": {},
   "source": [
    "#### MISTRAL7B-INSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start = time.time()\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Starting to run server1 models on n2c2_2008 data... \\n')\n",
    "    f.write(f'Running mistral7B instruct model on n2c2_2018 data... \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be07ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 06:02:27,679 - n2c2 - INFO - Parameters: \n",
      "{device: {device: cuda, load_8bit: true, num_gpus: 1}, general: {resources: {section_titles: resources/n2c2_sections_subpart.txt},\n",
      "    test: {dir: data/n2c2_2008_data, files: [n2c2_2008_test.csv]}, train: {dir: data/n2c2_2008_data,\n",
      "      files: [n2c2_2008_train.csv]}, val: {dir: data/n2c2_2008_data, files: [n2c2_2008_val.csv]}},\n",
      "  generation: {echo: false, judge_sent_end: false, max_new_tokens: 256, model_path: mistralai/Mistral-7B-Instruct-v0.1,\n",
      "    repetition_penalty: 1.0, temperature: 0}, intuitive_Asthma: {few_shot: true},\n",
      "  intuitive_CAD: {few_shot: true}, intuitive_CHF: {few_shot: true}, intuitive_Depression: {\n",
      "    few_shot: true}, intuitive_Diabetes: {few_shot: true}, intuitive_GERD: {few_shot: true},\n",
      "  intuitive_Gallstones: {few_shot: true}, intuitive_Gout: {few_shot: true}, intuitive_Hypercholesterolemia: {\n",
      "    few_shot: true}, intuitive_Hypertension: {few_shot: true}, intuitive_Hypertriglyceridemia: {\n",
      "    few_shot: true}, intuitive_OA: {few_shot: true}, intuitive_OSA: {few_shot: true},\n",
      "  intuitive_Obesity: {few_shot: true}, intuitive_PVD: {few_shot: true}, intuitive_Venous Insufficiency: {\n",
      "    few_shot: true}, logger: !!python/object/apply:logging.getLogger [n2c2], main: {\n",
      "    task_dirs: [few_shot_n2c2_2008_tasks]}, retrieval: {EMD: {distance_type: cosine,\n",
      "      embedding_type: fasttext}, OVERLAP: {distance_type: cosine, embedding_type: fasttext},\n",
      "    lowercase: true, method: OVERLAP, use_cuda: false}, textual_Asthma: {few_shot: true},\n",
      "  textual_CAD: {few_shot: true}, textual_CHF: {few_shot: true}, textual_Depression: {\n",
      "    few_shot: true}, textual_Diabetes: {few_shot: true}, textual_GERD: {few_shot: true},\n",
      "  textual_Gallstones: {few_shot: true}, textual_Gout: {few_shot: true}, textual_Hypercholesterolemia: {\n",
      "    few_shot: true}, textual_Hypertension: {few_shot: true}, textual_Hypertriglyceridemia: {\n",
      "    few_shot: true}, textual_OA: {few_shot: true}, textual_OSA: {few_shot: true},\n",
      "  textual_Obesity: {few_shot: true}, textual_PVD: {few_shot: true}, textual_Venous Insufficiency: {\n",
      "    few_shot: true}}\n",
      "\n",
      "2024-03-02 06:02:27,680 - n2c2 - INFO - available devices: 1\n",
      "2024-03-02 06:02:27,681 - n2c2 - INFO - current device: 0\n",
      "2024-03-02 06:02:28,131 - n2c2 - INFO - Load fastchat model mistralai/Mistral-7B-Instruct-v0.1\n",
      "100%|██████████| 2/2 [04:24<00:00, 132.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralAttention(\n",
      "          (q_proj): CLinear()\n",
      "          (k_proj): CLinear()\n",
      "          (v_proj): CLinear()\n",
      "          (o_proj): CLinear()\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): CLinear()\n",
      "          (up_proj): CLinear()\n",
      "          (down_proj): CLinear()\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): CLinear()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 06:06:59,183 - n2c2 - INFO - Load retriever\n"
     ]
    }
   ],
   "source": [
    "mistral7b_instruct_model = LLMModel(\n",
    "    config_file='./model-configs/mistral7b_instruct_n2c2_2008.yml',\n",
    "    title_prefix='3-n2c2_2008-textual-few-shot-mistral-7b-instruct', \n",
    "    task_names = ['textual_Asthma', 'textual_CAD', 'textual_CHF', 'textual_Depression', 'textual_Diabetes',\n",
    "              'textual_Gallstones', 'textual_GERD', 'textual_Gout', 'textual_Hypertension', 'textual_Hypercholesterolemia', \n",
    "              'textual_Hypertriglyceridemia', 'textual_OA', 'textual_Obesity', 'textual_OSA', 'textual_PVD',   \n",
    "              'textual_Venous Insufficiency'],\n",
    "    is_multiclass=True)\n",
    "\n",
    "mistral7b_instruct_model.setupModelForPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bf3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 06:08:37,799 - n2c2 - INFO - Load data\n",
      "2024-03-02 06:08:37,976 - n2c2 - INFO - Load data\n",
      "2024-03-02 06:08:38,048 - n2c2 - INFO - Load data\n",
      "  0%|          | 0/438 [00:00<?, ?it/s]/home/tai/n2c2_test/llm_utils.py:211: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'U' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  prediction_df.loc[prediction_df['id'] == text_id, task_name] = pred_answer\n",
      " 42%|████▏     | 185/438 [13:34<18:56,  4.49s/it]"
     ]
    }
   ],
   "source": [
    "temp_start = time.time()\n",
    "elapsed_time = temp_start - model_start\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Finished setting up mistral7b_instruct_model model on n2c2_2008 data: {elapsed_time}\\n')\n",
    "\n",
    "for example_name in example_names:\n",
    "    temp_end = time.time()\n",
    "    elapsed_time = temp_end - temp_start\n",
    "\n",
    "    mistral7b_instruct_model.load2006and2008ModelPredictions(example_name)\n",
    "\n",
    "    with open(log_file_name, 'a') as f:\n",
    "        f.write(f'Finished running {example_name} for mistral7b_instruct_model model on n2c2_2008 data: {elapsed_time}\\n')\n",
    "    \n",
    "    temp_start = time.time()\n",
    "        \n",
    "\n",
    "model_end = time.time()\n",
    "elapsed_time = model_end - model_start\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Finished running mistral7b_instruct_model model on n2c2_2008 data: {elapsed_time}\\n')\n",
    "\n",
    "del mistral7b_instruct_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced9520",
   "metadata": {},
   "source": [
    "#### ENDING CLEANUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "elapsed_time = end - model_start\n",
    "\n",
    "with open(log_file_name, 'a') as f:\n",
    "    f.write(f'Finished running models on server 1 on n2c2_2008 data for textual tasks: {elapsed_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9906cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f697641-709c-4e60-984b-8491fd8567e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastchat",
   "language": "python",
   "name": "fastchat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
